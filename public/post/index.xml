<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on A Hugo website</title>
    <link>/post/</link>
    <description>Recent content in Posts on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ensembling models</title>
      <link>/2021/06/25/ensembling-models/</link>
      <pubDate>Fri, 25 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/06/25/ensembling-models/</guid>
      <description>One of the great advantages of the tidymodels framework is the possibility to ensemble several models together in order to achieve better predicitions. The following example is largely based on the video from David Robinson for its series “Machine Learning Monday” available here: https://www.youtube.com/watch?v=HBZyqkVjUgY&amp;amp;t=4962s
The purpose of the exercise is to predict usersratings for board games from various predictor variables. The dataset is coming from a SLICED session from Kaggle and is available here: https://www.</description>
    </item>
    
    <item>
      <title>Spam text identification</title>
      <link>/2021/05/05/spam-text-identification/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/05/05/spam-text-identification/</guid>
      <description>The following example is simple attempt to classify received text messages as either “spam” or valid text “ham”. This example is interesting as it deals with some simple concepts of machine learning but also some processing for natural languages. This post has been mainly inspired by a chapter in the book “Machine Learning with R” by Brett Lantz, with a slightly different approach by relying mostly on Tidymodels and Tidyverse syntax.</description>
    </item>
    
    <item>
      <title>Diabete prediction using deep learning</title>
      <link>/2021/05/04/diabete-prediction-using-deep-learning/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/05/04/diabete-prediction-using-deep-learning/</guid>
      <description>We will see in this example how to use a neural network to predict the apparition of a case of diabete based on several predictor variables such as glucose concentration in the blood test, blood pressure, age, number of pregnencies, levels of insulin… In the column Outcome, a 1 corresponds to a diagnosed a diabete case.
library(tidyverse) library(tidymodels) library(keras) diabetes &amp;lt;- read_csv(&amp;quot;diabetes.csv&amp;quot;) predvars &amp;lt;- c(&amp;quot;Pregnancies&amp;quot;, &amp;quot;Glucose&amp;quot;, &amp;quot;BloodPressure&amp;quot;, &amp;quot;BMI&amp;quot;, &amp;quot;DiabetesPedigreeFunction&amp;quot;) df &amp;lt;- diabetes %&amp;gt;% select(Outcome, Pregnancies:Age) head(diabetes) ## # A tibble: 6 x 9 ## Pregnancies Glucose BloodPressure SkinThickness Insulin BMI DiabetesPedigre… ## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; ## 1 6 148 72 35 0 33.</description>
    </item>
    
    <item>
      <title>Predicting avocado price with several models</title>
      <link>/2021/04/23/predicting-avocado-price-with-several-models/</link>
      <pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/23/predicting-avocado-price-with-several-models/</guid>
      <description>To explore this nice dataset about the avocado sales in the US between the year 2015 and 2018, we will have the possibility to look into some pretty interesting visualization features, and some nice tools of the tidymodel package. We will try to predict the average price of the avocado based on the other features of the dataset.
library(tidyverse) library(tidymodels) library(lubridate) library(viridis) avocado &amp;lt;- read_csv(&amp;quot;avocado.csv&amp;quot;) ## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] avocado &amp;lt;-avocado %&amp;gt;% select(-X1) %&amp;gt;% janitor::clean_names() head(avocado) ## # A tibble: 6 x 13 ## date average_price total_volume x4046 x4225 x4770 total_bags small_bags ## &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; ## 1 2015-12-27 1.</description>
    </item>
    
    <item>
      <title>Simple image classification usinge a CNN</title>
      <link>/2021/04/19/simple-image-classification-usinge-a-cnn/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/19/simple-image-classification-usinge-a-cnn/</guid>
      <description>This post describes a simple way to perform multi-class classification using a convolutional neural networl (CNN). The data is composed of 60 000 images of clothing of 10 types (shoes, T-shirt, pants…). The purpose of the exercice is to accurately classify the testing dataset composed of another 10 000 of these types of pictures
First we have to download the data. Fortunately there is a built-in function in Keras for training purposes.</description>
    </item>
    
    <item>
      <title>Classification with Tidymodels</title>
      <link>/2021/04/17/classification-with-tidymodels/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/04/17/classification-with-tidymodels/</guid>
      <description>This is a simple example of data classification using tree bases models with the Tidymodels package. The data comme from a classical dataset about credit default with various explainatory variables associated.
Data import and splitting into training and test sets credit &amp;lt;- read.csv(&amp;quot;credit.csv&amp;quot;) credit &amp;lt;- credit %&amp;gt;% mutate_if(is.character, factor) %&amp;gt;% mutate(default = factor(default), dependents = factor(dependents)) %&amp;gt;% as_tibble() head(credit) ## # A tibble: 6 x 21 ## checking_balance months_loan_duration credit_history purpose amount ## &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt; ## 1 &amp;lt; 0 DM 6 critical radio/tv 1169 ## 2 1 - 200 DM 48 repaid radio/tv 5951 ## 3 unknown 12 critical education 2096 ## 4 &amp;lt; 0 DM 42 repaid furniture 7882 ## 5 &amp;lt; 0 DM 24 delayed car (new) 4870 ## 6 unknown 36 repaid education 9055 ## # … with 16 more variables: savings_balance &amp;lt;fct&amp;gt;, employment_length &amp;lt;fct&amp;gt;, ## # installment_rate &amp;lt;int&amp;gt;, personal_status &amp;lt;fct&amp;gt;, other_debtors &amp;lt;fct&amp;gt;, ## # residence_history &amp;lt;int&amp;gt;, property &amp;lt;fct&amp;gt;, age &amp;lt;int&amp;gt;, installment_plan &amp;lt;fct&amp;gt;, ## # housing &amp;lt;fct&amp;gt;, existing_credits &amp;lt;int&amp;gt;, default &amp;lt;fct&amp;gt;, dependents &amp;lt;fct&amp;gt;, ## # telephone &amp;lt;fct&amp;gt;, foreign_worker &amp;lt;fct&amp;gt;, job &amp;lt;fct&amp;gt; First let’s have a bried look at the data.</description>
    </item>
    
    <item>
      <title>Cartes chloroplèthes</title>
      <link>/2021/04/13/cartes-chloropl%C3%A8thes/</link>
      <pubDate>Tue, 13 Apr 2021 11:47:03 +0000</pubDate>
      
      <guid>/2021/04/13/cartes-chloropl%C3%A8thes/</guid>
      <description>Comment utiliser une carte pour representer des données géographiques sous R Télécharger la carte désirée La première étape consiste à récupérer une carte de la zone d’intérêt. Par exemple sur le site data.gouv.fr les cartes de France à différentes échelles peuvent être téléchargées. Nous utiliserons ici les cartes au format .SHP qui peuvent être lues par le package sf.
https://www.data.gouv.fr/en/datasets/contours-des-regions-francaises-sur-openstreetmap/
Carte des régions Carte des départements
 Charger la carte dans R Après avoir téléchargé l’archive contenant la carte des départements dans notre working-directory, et avoir extrait l’archive, on peut accèder au contenu de la carte.</description>
    </item>
    
    <item>
      <title>Installer des packages R sur serveur AWS - problèmes et solutions</title>
      <link>/2021/04/13/installer-des-packages-r-sur-serveur-aws-probl%C3%A8mes-et-solutions/</link>
      <pubDate>Tue, 13 Apr 2021 11:38:09 +0000</pubDate>
      
      <guid>/2021/04/13/installer-des-packages-r-sur-serveur-aws-probl%C3%A8mes-et-solutions/</guid>
      <description>En essayant d’installer des packages pour R sur une instance AWS, il arrive parfois que l’installation n’aboutisse tout simplement pas. Le programme apparaît alors complètement bloqué, notamment lors des étapes de compilation.
Ceci est particulièrement impactant pour des packages comme dplyr ou sf qui sont assez lourds et demandent une quantité de mémoire assez importante pour être installés.
La solution consiste à utiliser le gestionnaire de paquets de Linux pour réaliser cette installation.</description>
    </item>
    
    <item>
      <title>How to get a Half-shiny app?</title>
      <link>/2021/03/29/how-to-get-a-half-shiny-app/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/03/29/how-to-get-a-half-shiny-app/</guid>
      <description>Do you want a half-shiny App ? Because that’s how you get a nice half-shiny app with half of your screen being grey like that :
For that I just had to split my UI and Server functions the wrong way. Instead off having an “app.R” in your application folder:
Besides the lame jokes, it took me ages to figure out what was actually going around. Turns out I was just following bad practices for splitting my app.</description>
    </item>
    
    <item>
      <title>Hello world of neural networks</title>
      <link>/2021/03/25/hello-world-of-neural-networks/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/2021/03/25/hello-world-of-neural-networks/</guid>
      <description>Below is a very simple example of the typical analysis done with keras as a demonstration of the use of a neural network. It starts as usual by loading the necessary packages in this case only the keras package will be necessary. The data correspond to hand-written digits whose images have been scanned and preprocessed so that the actual drawing is centered in a 28 * 28 pixels image, with the corresponding digits specified in the label y part of the df dataset.</description>
    </item>
    
    <item>
      <title>matlab-functions-in-r</title>
      <link>/1/01/01/matlab-functions-in-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/matlab-functions-in-r/</guid>
      <description>Introduction As someone who learned to do data science using Matlab, there are a few functions which I found extremely convenient in those days that did not have a direct equivalent in R. Two of them are the clear and clearvars functions.
First of all, I know that in Rstudio the broomstick in the “Environment” part of the UI does exactly what clear does: removing all variables from the workspace.</description>
    </item>
    
  </channel>
</rss>
